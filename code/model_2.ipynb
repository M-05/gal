{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "970c2194",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45802006",
   "metadata": {},
   "source": [
    "- 목적 : model_1을 통과하여 imp로 처리된 데이터를 다시 분류한다.\n",
    "- 학습 데이터 : dktc_imp, 4개의 레이블이 달린 기타 imp 대화셋 추가 가능.\n",
    "- 참고사항 : immoral에서 수동으로 imp 추출해볼까도 생각중이지만... ... ... ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3460bbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras-bert\n",
    "# !pip install keras-radam\n",
    "# !pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c358b41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 import 및 주요 라이브러리 버전 확인 \n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import re\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras as keras\n",
    "from keras.models import load_model\n",
    "from keras import backend as K \n",
    "from keras import Input, Model\n",
    "from keras import optimizers\n",
    "\n",
    "import codecs\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "import json\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "warnings.filterwarnings(action='ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "# tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "from keras_bert import load_trained_model_from_checkpoint, load_vocabulary\n",
    "from keras_bert import Tokenizer\n",
    "from keras_bert import AdamWarmup, calc_train_steps\n",
    "\n",
    "from keras_radam import RAdam\n",
    "from keras_radam.training import RAdamOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee2de87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import encoding_korbert as enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "169a5c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dktc_imp_df = pd.read_csv(\"./data/dktc_imp.csv\", usecols=['class','conversation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d1c0f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    dktc_imp_df = dktc_imp_df.sample(frac=1).reset_index(drop=True) #많이 섞기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95285144",
   "metadata": {},
   "outputs": [],
   "source": [
    "dktc_imp_df[\"class\"] = dktc_imp_df[\"class\"].astype('category')\n",
    "dktc_imp_df[\"class\"] = dktc_imp_df[\"class\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "583afa78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>야 거기 찐따. 일로와봐.\\n저요.?\\n여기에 찐따가 너 말고 누가 있어.\\n왜요....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>자네집 개가 우리집 개를 물어서 피가 나고 살점이 뜯겨서 병원까지 다녀왔네\\n아 미...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>이거봐봐 우리반 길동이 지 올린건데 뭐냐 이거 \\n 완전 표정 왜저래 지가 이쁜줄 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>내가 쟤랑 왜 같은 조냐고\\n야 좀 참아 어차피 쟤가 다 해줄걸?\\n그런가? 하긴....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>아가씨 우리랑 같이 놀까?\\n제가 막차가 얼마 안 남아서요. 죄송합니다.\\n에이 왜...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3945</th>\n",
       "      <td>3</td>\n",
       "      <td>내일까지 해결하는 게 좋을거야\\n불가능합니다. 시간이 너무 촉박해요\\n촉박이라.\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3946</th>\n",
       "      <td>2</td>\n",
       "      <td>김과장 이리와보게\\n부장님 무슨일로 부르셨습니까??\\n내가 하라고 한 프로젝트를 이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3947</th>\n",
       "      <td>2</td>\n",
       "      <td>모레 회사 단합회에서 장기자랑 있는 거 알고있지?\\n네 과장님.\\n그래서 말인데 난...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3948</th>\n",
       "      <td>0</td>\n",
       "      <td>야 거기 너 일로 와바\\n네? 저요?\\n너 말고 누구겠냐\\n저 아무것도 없어요.\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3949</th>\n",
       "      <td>2</td>\n",
       "      <td>씨 지금 뭐하니?\\n 아 네 집이에요.\\n 아 내가 지금 그 근차 지나가는데 혹시 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3950 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class                                       conversation\n",
       "0         0  야 거기 찐따. 일로와봐.\\n저요.?\\n여기에 찐따가 너 말고 누가 있어.\\n왜요....\n",
       "1         3  자네집 개가 우리집 개를 물어서 피가 나고 살점이 뜯겨서 병원까지 다녀왔네\\n아 미...\n",
       "2         1  이거봐봐 우리반 길동이 지 올린건데 뭐냐 이거 \\n 완전 표정 왜저래 지가 이쁜줄 ...\n",
       "3         1  내가 쟤랑 왜 같은 조냐고\\n야 좀 참아 어차피 쟤가 다 해줄걸?\\n그런가? 하긴....\n",
       "4         1  아가씨 우리랑 같이 놀까?\\n제가 막차가 얼마 안 남아서요. 죄송합니다.\\n에이 왜...\n",
       "...     ...                                                ...\n",
       "3945      3  내일까지 해결하는 게 좋을거야\\n불가능합니다. 시간이 너무 촉박해요\\n촉박이라.\\n...\n",
       "3946      2  김과장 이리와보게\\n부장님 무슨일로 부르셨습니까??\\n내가 하라고 한 프로젝트를 이...\n",
       "3947      2  모레 회사 단합회에서 장기자랑 있는 거 알고있지?\\n네 과장님.\\n그래서 말인데 난...\n",
       "3948      0  야 거기 너 일로 와바\\n네? 저요?\\n너 말고 누구겠냐\\n저 아무것도 없어요.\\n...\n",
       "3949      2  씨 지금 뭐하니?\\n 아 네 집이에요.\\n 아 내가 지금 그 근차 지나가는데 혹시 ...\n",
       "\n",
       "[3950 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dktc_imp_df\n",
    "# 0: 갈취 대화, 1: 기타 괴롭힘 대화 , 2: 직장 내 괴롭힘 대화, 3: 협박 대화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf3c6c0",
   "metadata": {},
   "source": [
    "### train_validation_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcdbea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_train_df, model_2_val_df = train_test_split(dktc_imp_df, \n",
    "                                  test_size=0.2, \n",
    "                                  random_state=5555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08daa355",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_train_df.reset_index(drop=\"index\", inplace=True)\n",
    "model_2_val_df.reset_index(drop=\"index\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483f3b0e",
   "metadata": {},
   "source": [
    "### korBERT 불러와서 model_extra 빌딩& 파인튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfad6bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = enc.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85646499",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = enc.load_data(model_2_train_df)\n",
    "val_x, val_y = enc.load_data(model_2_val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d80fab3",
   "metadata": {},
   "source": [
    "### WandB 로그인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcdbc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login(key=\"fff4dcdf86063b9dafa0296b4abaeb7d3639da7d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab5cf11",
   "metadata": {},
   "source": [
    "### init_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1533ee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_config = {\n",
    "#     \"n_channel_1\" : 32,\n",
    "#     \"n_channel_2\" : 64,\n",
    "#     \"n_dense\" : 4,\n",
    "    \"learning_rate\" : 5e-5,\n",
    "    \"epochs\" : 5,\n",
    "    \"batch_size\" : 8,\n",
    "    \"weight_decay\" : 0.025,\n",
    "    \"optimizer\" : \"radam\",\n",
    "    \"loss\" : \"categorical_crossentropy\",\n",
    "#     \"loss\" : \"sparse_categorical_crossentropy\",\n",
    "    \"metrics\" : [\"accuracy\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807557bd",
   "metadata": {},
   "source": [
    "### sweep_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8d969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    \"metric\": {\"name\": \"val_loss\", \"goal\": \"minimize\"},\n",
    "    \"method\": \"random\",\n",
    "    \"parameters\": {\n",
    "        \"optimizer\" : {\n",
    "            'value' : 'radam'\n",
    "            },\n",
    "        \"batch_size\" : {\n",
    "            \"values\" : [8, 16] # OOM 에러시 바꿔주세용\n",
    "            },\n",
    "        \"learning_rate\" : {\n",
    "            \"min\" : 5e-5,\n",
    "            \"max\" : 5e-4 # 0에 가까울 수록\n",
    "            },\n",
    "        \"weight_decay\" : {\n",
    "            \"values\" : [0.025, 0.001]\n",
    "        },\n",
    "        \"epochs\" : {\n",
    "            \"distribution\" : \"int_uniform\",\n",
    "            \"min\" : 3,\n",
    "            \"max\" : 5\n",
    "            }\n",
    "                    \n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3099fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_path =\"./bert\" #상대경로 잡기\n",
    "\n",
    "SEQ_LEN = enc.SEQ_LEN\n",
    "\n",
    "config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
    "checkpoint_path = os.path.join(pretrained_path, 'bert_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b062e463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = load_trained_model_from_checkpoint(config_path,\n",
    "                                                checkpoint_path,\n",
    "                                                training=True,\n",
    "                                                trainable=True,\n",
    "                                                seq_len=SEQ_LEN)\n",
    "    \n",
    "    inputs = model.inputs[:2]\n",
    "    dense = model.layers[-3].output\n",
    "    \n",
    "    outputs = keras.layers.Dense(4, activation='softmax', \n",
    "                               kernel_initializer=keras.initializers.TruncatedNormal(stddev=0.02),\n",
    "                              name = 'real_output')(dense)\n",
    "\n",
    "    bert_model = keras.models.Model(inputs, outputs)\n",
    "\n",
    "    return bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4429527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def set_optimizer():\n",
    "#     if config.optimizer == \"radam\":\n",
    "#         return RAdamOptimizer(learning_rate=config.learning_rate, \n",
    "#                               weight_decay=config.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478fa9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = [\"갈취 대화\", \"기타 괴롭힘 대화\" , \"직장 내 괴롭힘 대화\", \"협박 대화\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ac2e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path= './saved'\n",
    "\n",
    "layer_num = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0661ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_callbacks():                       # 날짜 바꿔주세용\n",
    "    CK = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(path, \"model_2_weights_0419.{epoch:02d}-{val_loss:.2f}.h5\"),\n",
    "                                              monitor='val_loss',\n",
    "                                              save_best_only = True,\n",
    "                                              save_weights_only = True)\n",
    "\n",
    "    ES = tf.keras.callbacks.EarlyStopping(patience=1)\n",
    "    \n",
    "    return CK, ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f03c2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    global default_config\n",
    "\n",
    "    # wandb.init & config ok\n",
    "    run = wandb.init(project = 'model_2_0419', # 날짜만 변경해주세요\n",
    "                    entity = \"m05\",\n",
    "                    config = default_config)\n",
    "    config = wandb.config\n",
    "\n",
    "    # Model ok\n",
    "    model = build_model()    \n",
    "    \n",
    "    # optimizer 함수 불러오기 ok\n",
    "#     optimizer = set_optimizer()\n",
    "    if config.optimizer == \"radam\":\n",
    "        OPTIMIZER = RAdamOptimizer(learning_rate=config.learning_rate, \n",
    "                              weight_decay=config.weight_decay)\n",
    "    \n",
    "    # model.compile ok\n",
    "    model.compile(optimizer = OPTIMIZER,\n",
    "                  loss = config.loss,\n",
    "                  metrics= config.metrics)\n",
    "    \n",
    "    #keras_callbacks ok\n",
    "    CK, ES = keras_callbacks()\n",
    "    \n",
    "    # one_hot encoding\n",
    "    train_y = tf.one_hot(train_y, depth=4)\n",
    "    val_y = tf.one_hot(val_y, depth=4)\n",
    "    \n",
    "    # model.fit\n",
    "    model.fit(train_x, train_y,\n",
    "              epochs = config.epochs,\n",
    "              batch_size = config.batch_size,\n",
    "              validation_data = (val_x, val_y),\n",
    "              callbacks = [CK, ES , \n",
    "                           WandbCallback(training_data = (train_x[:30], train_y[:30]),\n",
    "                                         validation_data = (val_x[:30], val_y[:30]),\n",
    "                                        labels = CLASS_NAMES)])\n",
    "                                        \n",
    "    # weight 모델 저장\n",
    "    tf.keras.models.save_model(model, 'model_2')\n",
    "    \n",
    "    # validation Accuracy[Loss] 입력하기\n",
    "    wandb.log({\"Val_Accuracy \": model.history.history[\"val_accuracy\"][-1], \n",
    "               \"Val_Loss \": model.history.history[\"val_loss\"][-1]})\n",
    "    \n",
    "#     # evaluate test\n",
    "#     test_loss, test_accuracy = model.evaluate(test_x, test_y, verbose=2)\n",
    "    \n",
    "#     # wandb's 테이블쪽 column 추가하기\n",
    "#     wandb.log({\"Test Accuracy Rate: \" : round(test_accuracy * 100, 2),\n",
    "#                \"Test Error Rate: \" : round((1 - test_accuracy) * 100, 2)})\n",
    "    \n",
    "    run.finish() # run 종료"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19182639",
   "metadata": {},
   "source": [
    "### model.fit 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5370203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config,\n",
    "                       entity = 'm05', \n",
    "                       project = 'model_2_0419') # 날짜만 변경해주세요\n",
    "\n",
    "# run the sweep\n",
    "wandb.agent(sweep_id,\n",
    "            count=5, # 몇회 돌릴지 선택해주세요\n",
    "            function=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbfbb68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71f918ea",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e5f4536a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input-Token (InputLayer)        [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Segment (InputLayer)      [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (TokenEmbedding [(None, 256, 768), ( 91812096    Input-Token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Segment (Embedding)   (None, 256, 768)     1536        Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token-Segment (Add)   (None, 256, 768)     0           Embedding-Token[0][0]            \n",
      "                                                                 Embedding-Segment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Position (PositionEmb (None, 256, 768)     196608      Embedding-Token-Segment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Dropout (Dropout)     (None, 256, 768)     0           Embedding-Position[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Norm (LayerNormalizat (None, 256, 768)     1536        Embedding-Dropout[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 256, 768)     2362368     Embedding-Norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-1-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 256, 768)     0           Embedding-Norm[0][0]             \n",
      "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-1-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-1-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-1-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-1-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-2-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-1-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-2-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-2-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-2-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-2-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-3-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-2-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-3-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-3-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-3-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-3-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-4-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-3-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-4-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-4-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-4-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-4-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-5-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-4-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-5-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-5-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-5-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-5-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-5-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-6-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-5-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-6-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-6-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-6-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-6-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-6-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-7-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-6-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-7-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-7-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-7-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-7-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-7-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-8-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-7-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-8-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-8-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-8-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-8-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 256, 768)     2362368     Encoder-8-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-9-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 256, 768)     0           Encoder-8-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 256, 768)     1536        Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward (FeedForw (None, 256, 768)     4722432     Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Dropout ( (None, 256, 768)     0           Encoder-9-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Add (Add) (None, 256, 768)     0           Encoder-9-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-9-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Norm (Lay (None, 256, 768)     1536        Encoder-9-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 256, 768)     2362368     Encoder-9-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-9-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 256, 768)     1536        Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward (FeedFor (None, 256, 768)     4722432     Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Dropout  (None, 256, 768)     0           Encoder-10-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Add (Add (None, 256, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
      "                                                                 Encoder-10-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Norm (La (None, 256, 768)     1536        Encoder-10-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 256, 768)     2362368     Encoder-10-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-10-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 256, 768)     1536        Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward (FeedFor (None, 256, 768)     4722432     Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Dropout  (None, 256, 768)     0           Encoder-11-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Add (Add (None, 256, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
      "                                                                 Encoder-11-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Norm (La (None, 256, 768)     1536        Encoder-11-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 256, 768)     2362368     Encoder-11-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 256, 768)     0           Encoder-11-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 256, 768)     1536        Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward (FeedFor (None, 256, 768)     4722432     Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Dropout  (None, 256, 768)     0           Encoder-12-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Add (Add (None, 256, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
      "                                                                 Encoder-12-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Norm (La (None, 256, 768)     1536        Encoder-12-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Extract (Extract)               (None, 768)          0           Encoder-12-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "NSP-Dense (Dense)               (None, 768)          590592      Extract[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "real_output (Dense)             (None, 4)            3076        NSP-Dense[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 177,659,908\n",
      "Trainable params: 177,659,908\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2 = build_model()\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b214d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in model_2.layers[:layer_num]:\n",
    "#     layer.trainable = False # 층을 선택하여 freeze 하기."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
