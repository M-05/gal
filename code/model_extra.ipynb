{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99c0dd5e",
   "metadata": {},
   "source": [
    "# Model Extra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb1d0b3",
   "metadata": {},
   "source": [
    "- 목적 : 가진 데이터셋 dktc를 dktc_imp, dktc_exp 로 분류해서 저장한다.  \n",
    "- 학습 데이터 : 일상대화문, 비윤리대화문 중 intensity 2.0 이상을 추출한 데이터\n",
    "\n",
    "- 참고사항 : dktc를 분류하기 위한 모델이므로 학습에 dktc는 사용하지 않는다. 구조는 model_1과 같다. (not, exp을 분류하고 ood를 imp로 처리한다.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d5265f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras-bert\n",
    "!pip install keras-radam\n",
    "!pip install wandb\n",
    "\n",
    "# !pip install tensorflow==2.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cca214c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 import 및 주요 라이브러리 버전 확인 \n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import re\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras as keras\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "from keras import Input, Model\n",
    "from keras import optimizers\n",
    "\n",
    "import codecs\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "import json\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "# tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "from keras_bert import load_trained_model_from_checkpoint, load_vocabulary\n",
    "from keras_bert import Tokenizer\n",
    "from keras_bert import AdamWarmup, calc_train_steps\n",
    "\n",
    "from keras_radam import RAdam\n",
    "from keras_radam.training import RAdamOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d30a07ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-bert in /opt/conda/lib/python3.9/site-packages (0.89.0)\n",
      "Requirement already satisfied: keras-transformer==0.40.0 in /opt/conda/lib/python3.9/site-packages (from keras-bert) (0.40.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from keras-bert) (1.21.4)\n",
      "Requirement already satisfied: keras-embed-sim==0.10.0 in /opt/conda/lib/python3.9/site-packages (from keras-transformer==0.40.0->keras-bert) (0.10.0)\n",
      "Requirement already satisfied: keras-pos-embd==0.13.0 in /opt/conda/lib/python3.9/site-packages (from keras-transformer==0.40.0->keras-bert) (0.13.0)\n",
      "Requirement already satisfied: keras-position-wise-feed-forward==0.8.0 in /opt/conda/lib/python3.9/site-packages (from keras-transformer==0.40.0->keras-bert) (0.8.0)\n",
      "Requirement already satisfied: keras-layer-normalization==0.16.0 in /opt/conda/lib/python3.9/site-packages (from keras-transformer==0.40.0->keras-bert) (0.16.0)\n",
      "Requirement already satisfied: keras-multi-head==0.29.0 in /opt/conda/lib/python3.9/site-packages (from keras-transformer==0.40.0->keras-bert) (0.29.0)\n",
      "Requirement already satisfied: keras-self-attention==0.51.0 in /opt/conda/lib/python3.9/site-packages (from keras-multi-head==0.29.0->keras-transformer==0.40.0->keras-bert) (0.51.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: keras-radam in /opt/conda/lib/python3.9/site-packages (0.15.0)\n",
      "Requirement already satisfied: Keras in /opt/conda/lib/python3.9/site-packages (from keras-radam) (2.6.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from keras-radam) (1.21.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import encoding_korbert as enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670921ce",
   "metadata": {},
   "source": [
    "## 학습에 쓸 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18047dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_train_df = pd.read_csv(\"./data/daily_train.csv\", usecols=['class','conversation']) #일상대화 train 병합 데이터\n",
    "daily_val_df = pd.read_csv(\"./data/daily_val.csv\", usecols=['class','conversation']) #일상대화 val 병합 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33656b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "immoral_df = pd.read_csv(\"./data/immoral.csv\", usecols=['class','conversation'])\n",
    "# immoral_df = pd.read_csv(\"./data/immoral_over_1_5.csv\", usecols=['class','conversation'])\n",
    "# immoral_df = pd.read_csv(\"./data/immoral_over_1_7.csv\", usecols=['class','conversation'])\n",
    "# immoral_df = pd.read_csv(\"./data/immoral_over_2_v.csv\", usecols=['class','conversation'])\n",
    "immoral_df = immoral_df.sample(frac=1).reset_index(drop=True) # 행 섞기\n",
    "\n",
    "\n",
    "model_extra_exp_train_df, model_extra_exp_val_df = train_test_split(immoral_df, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3333e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플링 하고 싶을 때\n",
    "\n",
    "# daily_train_df =daily_train_df.sample(n=50, random_state=1004)\n",
    "# daily_val_df =daily_val_df.sample(n=10, random_state=1004)\n",
    "\n",
    "# model_extra_exp_train_df =model_extra_exp_train_df.sample(n=50, random_state=1004)\n",
    "# model_extra_exp_val_df =model_extra_exp_val_df.sample(n=10, random_state=1004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9f055f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_extra_train_df = pd.concat([daily_train_df, model_extra_exp_train_df], join=\"inner\")\n",
    "model_extra_train_df.reset_index(drop=\"index\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a4f3652",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_extra_val_df = pd.concat([daily_val_df, model_extra_exp_val_df], join=\"inner\")\n",
    "model_extra_val_df.reset_index(drop=\"index\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22e27f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    model_extra_train_df = model_extra_train_df.sample(frac=1).reset_index(drop=True) #많이 섞기\n",
    "\n",
    "for i in range(10):\n",
    "    model_extra_val_df = model_extra_val_df.sample(frac=1).reset_index(drop=True)#많이 섞기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f7c06cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_extra_train_df[\"class\"] = model_extra_train_df[\"class\"].astype('category')\n",
    "model_extra_train_df[\"class\"] = model_extra_train_df[\"class\"].cat.codes # 0:exp, 1:not\n",
    "\n",
    "model_extra_val_df[\"class\"] = model_extra_val_df[\"class\"].astype('category')\n",
    "model_extra_val_df[\"class\"] = model_extra_val_df[\"class\"].cat.codes # 0:exp, 1:not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee47c90f",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed2d7ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = enc.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b778b704",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90926/90926 [01:07<00:00, 1343.50it/s]\n",
      "100%|██████████| 11771/11771 [00:11<00:00, 1009.68it/s]\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = enc.load_data(model_extra_train_df)\n",
    "val_x, val_y = enc.load_data(model_extra_val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128f0a8f",
   "metadata": {},
   "source": [
    "### 모델 파인튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efbd0571",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /aiffel/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=\"fff4dcdf86063b9dafa0296b4abaeb7d3639da7d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510c98dd",
   "metadata": {},
   "source": [
    "### init_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "728b71e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_config = {\n",
    "#     \"n_channel_1\" : 32,\n",
    "#     \"n_channel_2\" : 64,\n",
    "#     \"n_dense\" : 1024,\n",
    "    \"learning_rate\" : 1e-4,\n",
    "    \"epochs\" : 5,\n",
    "    \"batch_size\" : 16,\n",
    "    \"weight_decay\" : 0.025,\n",
    "    \"optimizer\" : \"radam\",\n",
    "    \"loss\" : \"binary_crossentropy\",\n",
    "    \"metrics\" : [\"accuracy\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04081e2",
   "metadata": {},
   "source": [
    "### sweep_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b9f0db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    \"metric\": {\"name\": \"val_loss\", \"goal\": \"minimize\"},\n",
    "    \"method\": \"random\",\n",
    "    \"parameters\": {\n",
    "        \"optimizer\" : {\n",
    "            'value' : 'radam'\n",
    "            },\n",
    "        \"batch_size\" : {\n",
    "            \"values\" : [8, 16] # OOM 에러시 바꿔주세용\n",
    "            },\n",
    "        \"learning_rate\" : {\n",
    "            \"min\" : 1e-5,\n",
    "            \"max\" : 1e-4 # 0에 가까울 수록\n",
    "            },\n",
    "        \"weight_decay\" : {\n",
    "            \"values\" : [0.025, 0.001]\n",
    "        },\n",
    "        \"epochs\" : {\n",
    "            \"distribution\" : \"int_uniform\",\n",
    "            \"min\" : 3,\n",
    "            \"max\" : 5\n",
    "            }\n",
    "                    \n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "710448c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_path =\"./bert\" #상대경로 잡기\n",
    "\n",
    "SEQ_LEN = enc.SEQ_LEN\n",
    "\n",
    "config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
    "checkpoint_path = os.path.join(pretrained_path, 'bert_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41909a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = load_trained_model_from_checkpoint(config_path,\n",
    "                                                checkpoint_path,\n",
    "                                                training=True,\n",
    "                                                trainable=True,\n",
    "                                                seq_len=SEQ_LEN)\n",
    "    \n",
    "    inputs = model.inputs[:2]\n",
    "    dense = model.layers[-3].output\n",
    "    \n",
    "    outputs = keras.layers.Dense(1, activation='sigmoid', \n",
    "                               kernel_initializer=keras.initializers.TruncatedNormal(stddev=0.02),\n",
    "                              name = 'real_output')(dense)\n",
    "\n",
    "    bert_model = keras.models.Model(inputs, outputs)\n",
    "\n",
    "    return bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2ca3eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def set_optimizer():\n",
    "#     if config.optimizer == \"radam\":\n",
    "#         return RAdamOptimizer(learning_rate=config.learning_rate, \n",
    "#                               weight_decay=config.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b34bc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WandbCallback's labels\n",
    "CLASS_NAMES = [\"위협 대화\", \"일상 대화\"] # 0 exp(위협), 1 not(일상)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "586f9468",
   "metadata": {},
   "outputs": [],
   "source": [
    "path= './saved'\n",
    "\n",
    "layer_num = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc9d06af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_callbacks():                       # 날짜 바꿔주세용\n",
    "    CK = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(path, \"model_extra_weights_0420.{epoch:02d}-{val_loss:.2f}.h5\"),\n",
    "                                              monitor='val_loss',\n",
    "                                              save_best_only = True,\n",
    "                                              save_weights_only = True)\n",
    "\n",
    "    ES = tf.keras.callbacks.EarlyStopping(patience=1)\n",
    "    \n",
    "    return CK, ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "489d7b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    global default_config\n",
    "\n",
    "    # wandb.init & config ok\n",
    "    run = wandb.init(project = 'model_extra_0420', # 날짜만 변경해주세요\n",
    "                    entity = \"m05\",\n",
    "                    config = default_config)\n",
    "    config = wandb.config\n",
    "\n",
    "    # Model ok\n",
    "    model = build_model()    \n",
    "    \n",
    "    # optimizer 함수 불러오기 ok\n",
    "#     optimizer = set_optimizer()\n",
    "    if config.optimizer == \"radam\":\n",
    "        OPTIMIZER = RAdamOptimizer(learning_rate=config.learning_rate, \n",
    "                              weight_decay=config.weight_decay)\n",
    "    \n",
    "    # model.compile ok\n",
    "    model.compile(optimizer = OPTIMIZER,\n",
    "                  loss = config.loss,\n",
    "                  metrics= config.metrics)\n",
    "    \n",
    "    #keras_callbacks ok\n",
    "    CK, ES = keras_callbacks()\n",
    "    \n",
    "    # model.fit\n",
    "    model.fit(train_x, train_y,\n",
    "              epochs = config.epochs,\n",
    "              batch_size = config.batch_size,\n",
    "              validation_data = (val_x, val_y),\n",
    "              callbacks = [CK, ES , \n",
    "                           WandbCallback(training_data = (train_x[:30], train_y[:30]),\n",
    "                                         validation_data = (val_x[:30], val_y[:30]),\n",
    "                                        labels = CLASS_NAMES)])\n",
    "                                        \n",
    "    # weight 모델 저장\n",
    "    tf.keras.models.save_model(model, 'model_extra')\n",
    "    \n",
    "#     # evaluate test\n",
    "#     test_loss, test_accuracy = model.evaluate(test_x, test_y, verbose=2)\n",
    "    \n",
    "#     # wandb's 테이블쪽 column 추가하기\n",
    "#     wandb.log({\"Test Accuracy Rate: \" : round(test_accuracy * 100, 2),\n",
    "#                \"Test Error Rate: \" : round((1 - test_accuracy) * 100, 2)})\n",
    "    \n",
    "    run.finish() # run 종료"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abde423d",
   "metadata": {},
   "source": [
    "### model.fit 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db2a664f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: n7lg4n94\n",
      "Sweep URL: https://wandb.ai/m05/model_extra_0419/sweeps/n7lg4n94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qjtorvab with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.0954053526013697e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: radam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/aiffel/aiffel/aiffelthon/main_code/wandb/run-20230419_045712-qjtorvab</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/m05/model_extra_0419/runs/qjtorvab' target=\"_blank\">peachy-sweep-1</a></strong> to <a href='https://wandb.ai/m05/model_extra_0419' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/m05/model_extra_0419/sweeps/n7lg4n94' target=\"_blank\">https://wandb.ai/m05/model_extra_0419/sweeps/n7lg4n94</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/m05/model_extra_0419' target=\"_blank\">https://wandb.ai/m05/model_extra_0419</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/m05/model_extra_0419/sweeps/n7lg4n94' target=\"_blank\">https://wandb.ai/m05/model_extra_0419/sweeps/n7lg4n94</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/m05/model_extra_0419/runs/qjtorvab' target=\"_blank\">https://wandb.ai/m05/model_extra_0419/runs/qjtorvab</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "  15/5683 [..............................] - ETA: 1:39:21 - loss: 0.6968 - accuracy: 0.4125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config,\n",
    "                       entity = 'm05', \n",
    "                       project = 'model_extra_0420') # 날짜만 변경해주세요\n",
    "\n",
    "# run the sweep\n",
    "wandb.agent(sweep_id,\n",
    "            count=5, # 몇회 돌릴지 선택해주세요\n",
    "            function=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d608423",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae324b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_extra= build_model()\n",
    "# model_extra.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17f76edd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder-1-MultiHeadSelfAttention is not frozen, 고정안됨\n",
      "Encoder-1-MultiHeadSelfAttention-Dropout is not frozen, 고정안됨\n",
      "Encoder-1-MultiHeadSelfAttention-Add is not frozen, 고정안됨\n",
      "Encoder-1-MultiHeadSelfAttention-Norm is not frozen, 고정안됨\n",
      "Encoder-1-FeedForward is not frozen, 고정안됨\n",
      "Encoder-1-FeedForward-Dropout is not frozen, 고정안됨\n",
      "Encoder-1-FeedForward-Add is not frozen, 고정안됨\n",
      "Encoder-1-FeedForward-Norm is not frozen, 고정안됨\n",
      "Encoder-2-MultiHeadSelfAttention is not frozen, 고정안됨\n",
      "Encoder-2-MultiHeadSelfAttention-Dropout is not frozen, 고정안됨\n",
      "Encoder-2-MultiHeadSelfAttention-Add is not frozen, 고정안됨\n",
      "Encoder-2-MultiHeadSelfAttention-Norm is not frozen, 고정안됨\n",
      "Encoder-2-FeedForward is not frozen, 고정안됨\n",
      "Encoder-2-FeedForward-Dropout is not frozen, 고정안됨\n",
      "Encoder-2-FeedForward-Add is not frozen, 고정안됨\n",
      "Encoder-2-FeedForward-Norm is not frozen, 고정안됨\n",
      "Encoder-3-MultiHeadSelfAttention is not frozen, 고정안됨\n",
      "Encoder-3-MultiHeadSelfAttention-Dropout is not frozen, 고정안됨\n",
      "Encoder-3-MultiHeadSelfAttention-Add is not frozen, 고정안됨\n",
      "Encoder-3-MultiHeadSelfAttention-Norm is not frozen, 고정안됨\n",
      "Encoder-3-FeedForward is not frozen, 고정안됨\n",
      "Encoder-3-FeedForward-Dropout is not frozen, 고정안됨\n",
      "Encoder-3-FeedForward-Add is not frozen, 고정안됨\n",
      "Encoder-3-FeedForward-Norm is not frozen, 고정안됨\n",
      "Encoder-4-MultiHeadSelfAttention is not frozen, 고정안됨\n",
      "Encoder-4-MultiHeadSelfAttention-Dropout is not frozen, 고정안됨\n",
      "Encoder-4-MultiHeadSelfAttention-Add is not frozen, 고정안됨\n",
      "Encoder-4-MultiHeadSelfAttention-Norm is not frozen, 고정안됨\n",
      "Encoder-4-FeedForward is not frozen, 고정안됨\n",
      "Encoder-4-FeedForward-Dropout is not frozen, 고정안됨\n",
      "Encoder-4-FeedForward-Add is not frozen, 고정안됨\n",
      "Encoder-4-FeedForward-Norm is not frozen, 고정안됨\n",
      "Encoder-5-MultiHeadSelfAttention is not frozen, 고정안됨\n",
      "Encoder-5-MultiHeadSelfAttention-Dropout is not frozen, 고정안됨\n",
      "Encoder-5-MultiHeadSelfAttention-Add is not frozen, 고정안됨\n",
      "Encoder-5-MultiHeadSelfAttention-Norm is not frozen, 고정안됨\n",
      "Encoder-5-FeedForward is not frozen, 고정안됨\n",
      "Encoder-5-FeedForward-Dropout is not frozen, 고정안됨\n",
      "Encoder-5-FeedForward-Add is not frozen, 고정안됨\n",
      "Encoder-5-FeedForward-Norm is not frozen, 고정안됨\n",
      "Encoder-6-MultiHeadSelfAttention is not frozen, 고정안됨\n",
      "Encoder-6-MultiHeadSelfAttention-Dropout is not frozen, 고정안됨\n",
      "Encoder-6-MultiHeadSelfAttention-Add is not frozen, 고정안됨\n",
      "Encoder-6-MultiHeadSelfAttention-Norm is not frozen, 고정안됨\n",
      "Encoder-6-FeedForward is not frozen, 고정안됨\n",
      "Encoder-6-FeedForward-Dropout is not frozen, 고정안됨\n",
      "Encoder-6-FeedForward-Add is not frozen, 고정안됨\n",
      "Encoder-6-FeedForward-Norm is not frozen, 고정안됨\n",
      "Encoder-7-MultiHeadSelfAttention is not frozen, 고정안됨\n",
      "Encoder-7-MultiHeadSelfAttention-Dropout is not frozen, 고정안됨\n",
      "Encoder-7-MultiHeadSelfAttention-Add is not frozen, 고정안됨\n",
      "Encoder-7-MultiHeadSelfAttention-Norm is not frozen, 고정안됨\n",
      "Encoder-7-FeedForward is not frozen, 고정안됨\n",
      "Encoder-7-FeedForward-Dropout is not frozen, 고정안됨\n",
      "Encoder-7-FeedForward-Add is not frozen, 고정안됨\n",
      "Encoder-7-FeedForward-Norm is not frozen, 고정안됨\n",
      "Encoder-8-MultiHeadSelfAttention is not frozen, 고정안됨\n",
      "Encoder-8-MultiHeadSelfAttention-Dropout is not frozen, 고정안됨\n",
      "Encoder-8-MultiHeadSelfAttention-Add is not frozen, 고정안됨\n",
      "Encoder-8-MultiHeadSelfAttention-Norm is not frozen, 고정안됨\n",
      "Encoder-8-FeedForward is not frozen, 고정안됨\n",
      "Encoder-8-FeedForward-Dropout is not frozen, 고정안됨\n",
      "Encoder-8-FeedForward-Add is not frozen, 고정안됨\n",
      "Encoder-8-FeedForward-Norm is not frozen, 고정안됨\n",
      "Encoder-9-MultiHeadSelfAttention is not frozen, 고정안됨\n",
      "Encoder-9-MultiHeadSelfAttention-Dropout is not frozen, 고정안됨\n",
      "Encoder-9-MultiHeadSelfAttention-Add is not frozen, 고정안됨\n",
      "Encoder-9-MultiHeadSelfAttention-Norm is not frozen, 고정안됨\n",
      "Encoder-9-FeedForward is not frozen, 고정안됨\n",
      "Encoder-9-FeedForward-Dropout is not frozen, 고정안됨\n",
      "Encoder-9-FeedForward-Add is not frozen, 고정안됨\n",
      "Encoder-9-FeedForward-Norm is not frozen, 고정안됨\n",
      "Encoder-10-MultiHeadSelfAttention is not frozen, 고정안됨\n",
      "Encoder-10-MultiHeadSelfAttention-Dropout is not frozen, 고정안됨\n",
      "Encoder-10-MultiHeadSelfAttention-Add is not frozen, 고정안됨\n",
      "Encoder-10-MultiHeadSelfAttention-Norm is not frozen, 고정안됨\n",
      "Encoder-10-FeedForward is not frozen, 고정안됨\n",
      "Encoder-10-FeedForward-Dropout is not frozen, 고정안됨\n",
      "Encoder-10-FeedForward-Add is not frozen, 고정안됨\n",
      "Encoder-10-FeedForward-Norm is not frozen, 고정안됨\n",
      "Encoder-11-MultiHeadSelfAttention is not frozen, 고정안됨\n",
      "Encoder-11-MultiHeadSelfAttention-Dropout is not frozen, 고정안됨\n",
      "Encoder-11-MultiHeadSelfAttention-Add is not frozen, 고정안됨\n",
      "Encoder-11-MultiHeadSelfAttention-Norm is not frozen, 고정안됨\n",
      "Encoder-11-FeedForward is not frozen, 고정안됨\n",
      "Encoder-11-FeedForward-Dropout is not frozen, 고정안됨\n",
      "Encoder-11-FeedForward-Add is not frozen, 고정안됨\n",
      "Encoder-11-FeedForward-Norm is not frozen, 고정안됨\n",
      "Encoder-12-MultiHeadSelfAttention is not frozen, 고정안됨\n",
      "Encoder-12-MultiHeadSelfAttention-Dropout is not frozen, 고정안됨\n",
      "Encoder-12-MultiHeadSelfAttention-Add is not frozen, 고정안됨\n",
      "Encoder-12-MultiHeadSelfAttention-Norm is not frozen, 고정안됨\n",
      "Encoder-12-FeedForward is not frozen, 고정안됨\n",
      "Encoder-12-FeedForward-Dropout is not frozen, 고정안됨\n",
      "Encoder-12-FeedForward-Add is not frozen, 고정안됨\n",
      "Encoder-12-FeedForward-Norm is not frozen, 고정안됨\n"
     ]
    }
   ],
   "source": [
    "# #레이어의 trainable 출력해서 확인하기\n",
    "\n",
    "# for layer in model_extra.layers:\n",
    "#     if 'Encoder' in layer.name:\n",
    "#         if 'layer_0' in layer.name:\n",
    "#             if layer.trainable == False:\n",
    "#                 print(f'{layer.name} is frozen, 고정됨')\n",
    "#             else:\n",
    "#                 print(f'{layer.name} is not frozen, 고정안됨')\n",
    "#         elif layer.trainable == False:\n",
    "#             print(f'{layer.name} is frozen, 고정됨')\n",
    "#         else:\n",
    "#             print(f'{layer.name} is not frozen, 고정안됨')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd17f8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in model_extra.layers[:layer_num]:\n",
    "#     layer.trainable = False # 층을 선택하여 freeze 하기."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
